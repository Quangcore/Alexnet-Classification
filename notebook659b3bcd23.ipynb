{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":93855,"databundleVersionId":11168888,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport torchvision.models as models\n\nimport timm  # Thư viện timm cung cấp các mô hình transformer như DeiT","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.742534Z","iopub.execute_input":"2025-03-09T14:59:29.742856Z","iopub.status.idle":"2025-03-09T14:59:29.748104Z","shell.execute_reply.started":"2025-03-09T14:59:29.742823Z","shell.execute_reply":"2025-03-09T14:59:29.747122Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Sử dụng thiết bị: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.751020Z","iopub.execute_input":"2025-03-09T14:59:29.751263Z","iopub.status.idle":"2025-03-09T14:59:29.764003Z","shell.execute_reply.started":"2025-03-09T14:59:29.751235Z","shell.execute_reply":"2025-03-09T14:59:29.763148Z"}},"outputs":[{"name":"stdout","text":"Sử dụng thiết bị: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/Training_set.csv\")\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.764955Z","iopub.execute_input":"2025-03-09T14:59:29.765275Z","iopub.status.idle":"2025-03-09T14:59:29.789309Z","shell.execute_reply.started":"2025-03-09T14:59:29.765255Z","shell.execute_reply":"2025-03-09T14:59:29.788558Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"       filename                     label\n0   Image_1.jpg          SOUTHERN DOGFACE\n1   Image_2.jpg                    ADONIS\n2   Image_3.jpg            BROWN SIPROETA\n3   Image_4.jpg                   MONARCH\n4   Image_5.jpg  GREEN CELLED CATTLEHEART\n5   Image_6.jpg           CAIRNS BIRDWING\n6   Image_7.jpg  GREEN CELLED CATTLEHEART\n7   Image_8.jpg      EASTERN DAPPLE WHITE\n8   Image_9.jpg            BROWN SIPROETA\n9  Image_10.jpg               RED POSTMAN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1.jpg</td>\n      <td>SOUTHERN DOGFACE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_2.jpg</td>\n      <td>ADONIS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_3.jpg</td>\n      <td>BROWN SIPROETA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_4.jpg</td>\n      <td>MONARCH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_5.jpg</td>\n      <td>GREEN CELLED CATTLEHEART</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Image_6.jpg</td>\n      <td>CAIRNS BIRDWING</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Image_7.jpg</td>\n      <td>GREEN CELLED CATTLEHEART</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Image_8.jpg</td>\n      <td>EASTERN DAPPLE WHITE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Image_9.jpg</td>\n      <td>BROWN SIPROETA</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Image_10.jpg</td>\n      <td>RED POSTMAN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.790784Z","iopub.execute_input":"2025-03-09T14:59:29.791206Z","iopub.status.idle":"2025-03-09T14:59:29.796326Z","shell.execute_reply.started":"2025-03-09T14:59:29.791154Z","shell.execute_reply":"2025-03-09T14:59:29.795452Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"5000"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"if 'label' in df.columns:\n    num_classes = df['label'].nunique()\n    label_column = 'label'\n    print(f\"Số lớp bướm khác nhau: {num_classes}\")\nelse:\n    possible_label_columns = ['category', 'class', 'type', 'species']\n    for col in possible_label_columns:\n        if col in df.columns:\n            label_column = col\n            num_classes = df[col].nunique()\n            print(f\"Tìm thấy cột nhãn: {label_column}\")\n            print(f\"Số lớp bướm khác nhau: {num_classes}\")\n            break\n    else:\n        print(\"Không tìm thấy cột nhãn rõ ràng. Giả định cột thứ hai là nhãn.\")\n        label_column = df.columns[1]\n        num_classes = df[label_column].nunique()\n        print(f\"Sử dụng cột {label_column} làm nhãn với {num_classes} lớp\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.797612Z","iopub.execute_input":"2025-03-09T14:59:29.797909Z","iopub.status.idle":"2025-03-09T14:59:29.809135Z","shell.execute_reply.started":"2025-03-09T14:59:29.797888Z","shell.execute_reply":"2025-03-09T14:59:29.807979Z"}},"outputs":[{"name":"stdout","text":"Số lớp bướm khác nhau: 75\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.810146Z","iopub.execute_input":"2025-03-09T14:59:29.810508Z","iopub.status.idle":"2025-03-09T14:59:29.819403Z","shell.execute_reply.started":"2025-03-09T14:59:29.810484Z","shell.execute_reply":"2025-03-09T14:59:29.818630Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport warnings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.820794Z","iopub.execute_input":"2025-03-09T14:59:29.820991Z","iopub.status.idle":"2025-03-09T14:59:29.830599Z","shell.execute_reply.started":"2025-03-09T14:59:29.820974Z","shell.execute_reply":"2025-03-09T14:59:29.829908Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"image_dir = \"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/train/train\"\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df[label_column], random_state=42)\nprint(f\"Số lượng ảnh huấn luyện: {len(train_df)}\")\nprint(f\"Số lượng ảnh validation: {len(val_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.831327Z","iopub.execute_input":"2025-03-09T14:59:29.831526Z","iopub.status.idle":"2025-03-09T14:59:29.852402Z","shell.execute_reply.started":"2025-03-09T14:59:29.831505Z","shell.execute_reply":"2025-03-09T14:59:29.851498Z"}},"outputs":[{"name":"stdout","text":"Số lượng ảnh huấn luyện: 4000\nSố lượng ảnh validation: 1000\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class ButterflyDataset(Dataset):\n    def __init__(self, data_frame, img_dir, transform=None, is_test=False, label_col='label'):\n        self.data_frame = data_frame\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.label_col = label_col\n        \n        if not is_test:\n            self.classes = sorted(data_frame[label_col].unique())\n            self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n    \n    def __len__(self):\n        return len(self.data_frame)\n    \n    def __getitem__(self, idx):\n        img_name = self.data_frame.iloc[idx, 0]\n        img_path = os.path.join(self.img_dir, img_name)\n        if not os.path.exists(img_path):\n            for ext in ['.jpg', '.jpeg', '.png']:\n                if os.path.exists(img_path + ext):\n                    img_path = img_path + ext\n                    break\n        try:\n            image = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            print(f\"Lỗi khi đọc ảnh {img_path}: {e}\")\n            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), color='gray')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if not self.is_test:\n            label_name = self.data_frame.iloc[idx, 1] if self.label_col=='label' else self.data_frame.iloc[idx][self.label_col]\n            label = self.class_to_idx[label_name]\n            return image, label\n        else:\n            return image, img_name\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n])\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\ntry:\n    train_dataset = ButterflyDataset(\n        data_frame=train_df,\n        img_dir=image_dir,\n        transform=train_transforms,\n        label_col=label_column\n    )\n    val_dataset = ButterflyDataset(\n        data_frame=val_df,\n        img_dir=image_dir,\n        transform=val_transforms,\n        label_col=label_column\n    )\n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n    \n    print(\"Dataset và DataLoader đã được tạo thành công!\")\nexcept Exception as e:\n    print(f\"Lỗi khi tạo dataset: {e}\")\n    raise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.900230Z","iopub.execute_input":"2025-03-09T14:59:29.900443Z","iopub.status.idle":"2025-03-09T14:59:29.918043Z","shell.execute_reply.started":"2025-03-09T14:59:29.900425Z","shell.execute_reply":"2025-03-09T14:59:29.917069Z"}},"outputs":[{"name":"stdout","text":"Dataset và DataLoader đã được tạo thành công!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from torchvision import models\n\n# Hàm tạo mô hình sử dụng AlexNet\ndef create_model(num_classes):\n    model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)  # Dùng pretrained weights\n    \n    # Freeze toàn bộ các layers ngoại trừ classifier\n    for param in model.features.parameters():\n        param.requires_grad = False\n    \n    # Thay đổi fully connected cuối cùng\n    model.classifier = nn.Sequential(\n        nn.Dropout(0.5),\n        nn.Linear(9216, 4096),\n        nn.ReLU(inplace=True),\n        nn.Dropout(0.5),\n        nn.Linear(4096, 1024),\n        nn.ReLU(inplace=True),\n        nn.Linear(1024, num_classes)\n    )\n    \n    return model\n\n# Khởi tạo mô hình\nmodel = create_model(num_classes)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:29.919541Z","iopub.execute_input":"2025-03-09T14:59:29.919840Z","iopub.status.idle":"2025-03-09T14:59:31.084323Z","shell.execute_reply.started":"2025-03-09T14:59:29.919808Z","shell.execute_reply":"2025-03-09T14:59:31.083568Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"EPOCH = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:31.086380Z","iopub.execute_input":"2025-03-09T14:59:31.086612Z","iopub.status.idle":"2025-03-09T14:59:31.090096Z","shell.execute_reply.started":"2025-03-09T14:59:31.086593Z","shell.execute_reply":"2025-03-09T14:59:31.089295Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Định nghĩa hàm mất mát với label smoothing\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n# Sử dụng optimizer Adam với weight decay\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n\n# Scheduler Cosine Annealing\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:59:31.091597Z","iopub.execute_input":"2025-03-09T14:59:31.091868Z","iopub.status.idle":"2025-03-09T14:59:31.102190Z","shell.execute_reply.started":"2025-03-09T14:59:31.091840Z","shell.execute_reply":"2025-03-09T14:59:31.101387Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"OUTPUT_PATH = '/kaggle/working/'\nif not os.path.exists(OUTPUT_PATH):\n    os.makedirs(OUTPUT_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:00:00.911815Z","iopub.execute_input":"2025-03-09T15:00:00.912220Z","iopub.status.idle":"2025-03-09T15:00:00.916556Z","shell.execute_reply.started":"2025-03-09T15:00:00.912149Z","shell.execute_reply":"2025-03-09T15:00:00.915814Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import torch\nimport os\nfrom tqdm import tqdm\ndef train_model(model, train_loader, val_loader, epoch, criterion, optimizer, scheduler=None):\n    train_losses, train_accs = [], []\n    val_losses, val_accs = [], []    \n    best_val_loss = float('inf')\n    \n    for epochs in range(epoch):\n        model.train()\n        train_loss, train_correct, train_total = 0, 0, 0\n        \n        for images, labels in tqdm(train_loader, desc=f'Epoch {epochs+1}/{epoch} [Train]'):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.size(0)\n            train_correct += (outputs.argmax(1) == labels).sum().item()\n            train_total += labels.size(0)\n        \n        history['train_losses'].append(train_loss / len(train_loader.dataset))\n        history['train_accs'].append(train_correct / train_total)\n        \n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=f'Epoch {epochs+1}/{epoch} [Val]'):\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item() * images.size(0)\n                val_correct += (outputs.argmax(1) == labels).sum().item()\n                val_total += labels.size(0)\n        epoch_val_loss = val_loss / len(val_loader.dataset)\n        history['val_losses'].append(val_loss / len(val_loader.dataset))\n        history['val_accs'].append(val_correct / val_total)\n\n        print(f'\\nEpoch {epochs+1}/{epoch}: Train Loss: {history[\"train_losses\"][-1]:.4f}, Train Acc: {history[\"train_accs\"][-1]:.4f}, Val Loss: {history[\"val_losses\"][-1]:.4f}, Val Acc: {history[\"val_accs\"][-1]:.4f}')\n        if scheduler:\n            scheduler.step()\n            \n        if epoch_val_loss < best_val_loss:\n            best_val_loss = epoch_val_loss\n            torch.save(model.state_dict(), os.path.join(OUTPUT_PATH, 'alexnet_model.pth'))\n\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:00:02.142580Z","iopub.execute_input":"2025-03-09T15:00:02.142872Z","iopub.status.idle":"2025-03-09T15:00:02.152264Z","shell.execute_reply.started":"2025-03-09T15:00:02.142850Z","shell.execute_reply":"2025-03-09T15:00:02.151264Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"history = {'train_losses': [], 'train_accs': [], 'val_losses': [], 'val_accs': []}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:00:04.281790Z","iopub.execute_input":"2025-03-09T15:00:04.282096Z","iopub.status.idle":"2025-03-09T15:00:04.286081Z","shell.execute_reply.started":"2025-03-09T15:00:04.282072Z","shell.execute_reply":"2025-03-09T15:00:04.285122Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"history = train_model(model, train_loader, val_loader, 20, criterion, optimizer, scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:00:06.144597Z","iopub.execute_input":"2025-03-09T15:00:06.144909Z","iopub.status.idle":"2025-03-09T15:03:43.254409Z","shell.execute_reply.started":"2025-03-09T15:00:06.144885Z","shell.execute_reply":"2025-03-09T15:03:43.253279Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.19it/s]\nEpoch 1/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/20: Train Loss: 2.3375, Train Acc: 0.5200, Val Loss: 1.7419, Val Acc: 0.7250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.01it/s]\nEpoch 2/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/20: Train Loss: 2.0170, Train Acc: 0.6192, Val Loss: 1.5917, Val Acc: 0.7670\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.29it/s]\nEpoch 3/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/20: Train Loss: 1.8977, Train Acc: 0.6562, Val Loss: 1.5194, Val Acc: 0.7870\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.16it/s]\nEpoch 4/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/20: Train Loss: 1.7920, Train Acc: 0.7020, Val Loss: 1.4999, Val Acc: 0.8120\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.85it/s]\nEpoch 5/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/20: Train Loss: 1.7273, Train Acc: 0.7200, Val Loss: 1.4251, Val Acc: 0.8290\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.23it/s]\nEpoch 6/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/20: Train Loss: 1.6751, Train Acc: 0.7362, Val Loss: 1.4302, Val Acc: 0.8300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.21it/s]\nEpoch 7/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/20: Train Loss: 1.6035, Train Acc: 0.7658, Val Loss: 1.3510, Val Acc: 0.8560\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.88it/s]\nEpoch 8/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/20: Train Loss: 1.5699, Train Acc: 0.7755, Val Loss: 1.3461, Val Acc: 0.8620\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.37it/s]\nEpoch 9/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/20: Train Loss: 1.5315, Train Acc: 0.7890, Val Loss: 1.3275, Val Acc: 0.8700\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.39it/s]\nEpoch 10/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/20: Train Loss: 1.4832, Train Acc: 0.8043, Val Loss: 1.3208, Val Acc: 0.8660\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.85it/s]\nEpoch 11/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/20: Train Loss: 1.4486, Train Acc: 0.8203, Val Loss: 1.3042, Val Acc: 0.8700\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.26it/s]\nEpoch 12/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/20: Train Loss: 1.4245, Train Acc: 0.8267, Val Loss: 1.2810, Val Acc: 0.8810\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.38it/s]\nEpoch 13/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/20: Train Loss: 1.3909, Train Acc: 0.8395, Val Loss: 1.2711, Val Acc: 0.8800\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.88it/s]\nEpoch 14/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/20: Train Loss: 1.3545, Train Acc: 0.8545, Val Loss: 1.2612, Val Acc: 0.8870\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.38it/s]\nEpoch 15/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/20: Train Loss: 1.3521, Train Acc: 0.8518, Val Loss: 1.2690, Val Acc: 0.8770\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.46it/s]\nEpoch 16/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/20: Train Loss: 1.3335, Train Acc: 0.8602, Val Loss: 1.2573, Val Acc: 0.8850\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.03it/s]\nEpoch 17/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/20: Train Loss: 1.3336, Train Acc: 0.8582, Val Loss: 1.2518, Val Acc: 0.8890\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.36it/s]\nEpoch 18/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/20: Train Loss: 1.3191, Train Acc: 0.8630, Val Loss: 1.2488, Val Acc: 0.8870\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.40it/s]\nEpoch 19/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/20: Train Loss: 1.3005, Train Acc: 0.8695, Val Loss: 1.2480, Val Acc: 0.8880\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.12it/s]\nEpoch 20/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.78it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/20: Train Loss: 1.3209, Train Acc: 0.8562, Val Loss: 1.2480, Val Acc: 0.8880\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"Test_dir = \"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/test/test\"\ndef process_test_folder(test_dir, transform):\n    if not os.path.exists(test_dir):\n        print(f\"Không tìm thấy thư mục test: {test_dir}\")\n        return None\n    \n    # Quét tất cả thư mục con và thu thập file ảnh hợp lệ\n    test_files = []\n    val_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n    \n    for root, dirs, files in os.walk(test_dir):\n        for file in files:\n            if file.lower().endswith(val_extensions):\n                # Lấy đường dẫn tương đối so với test_dir\n                rel_path = os.path.relpath(os.path.join(root, file), test_dir)\n                test_files.append(rel_path)\n    \n    if not test_files:\n        print(\"Không tìm thấy file ảnh hợp lệ trong thư mục test!\")\n        return None\n    \n    print(f\"Đã tìm thấy {len(test_files)} ảnh trong thư mục test và các thư mục con.\")\n    test_df = pd.DataFrame({'image': test_files})\n\n    class TestDataset(Dataset):\n        def __init__(self, file_list, dir_path, transform=None):\n            self.file_list = file_list\n            self.dir_path = dir_path\n            self.transform = transform\n        \n        def __len__(self):\n            return len(self.file_list)\n        \n        def __getitem__(self, idx):\n            img_name = self.file_list[idx]\n            img_path = os.path.join(self.dir_path, img_name)\n            \n            # Kiểm tra và xử lý lỗi đường dẫn\n            if not os.path.isfile(img_path):\n                print(f\"Lỗi đường dẫn: {img_path} không phải là file!\")\n                return torch.zeros((3, 224, 224)), \"invalid\"\n            \n            try:\n                image = Image.open(img_path).convert('RGB')\n                if self.transform:\n                    image = self.transform(image)\n                return image, img_name\n            except Exception as e:\n                print(f\"Lỗi khi xử lý ảnh {img_path}: {str(e)}\")\n                return torch.zeros((3, 224, 224)), \"invalid\"\n\n    test_dataset = TestDataset(test_df['image'].values, test_dir, transform)\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=64,\n        shuffle=False,\n        num_workers=2,\n        collate_fn=lambda x: (torch.stack([item[0] for item in x]), [item[1] for item in x])\n    )\n    \n    return test_loader\n\n# CẬP NHẬT HÀM DỰ ĐOÁN\ndef predict_and_submit(model, test_loader, class_mapping, output_path):\n    model.eval()\n    predictions = []\n    filenames = []\n    idx_to_class = {v: k for k, v in class_mapping.items()}\n    \n    with torch.no_grad():\n        for images, batch_names in tqdm(test_loader, desc=\"Đang dự đoán...\"):\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            predictions.extend([idx_to_class[idx.item()] for idx in predicted])\n            filenames.extend(batch_names)\n    \n    # Lọc các dự đoán không hợp lệ\n    val_data = [(f, p) for f, p in zip(filenames, predictions) if f != \"invalid\"]\n    \n    submission_df = pd.DataFrame({\n        'Id': [f for f, p in val_data],\n        'Category': [p for f, p in val_data]\n    })\n    \n    submission_path = os.path.join(output_path, 'submission.csv')\n    submission_df.to_csv(submission_path, index=False)\n    print(f\"Đã tạo file submission với {len(submission_df)} dự đoán hợp lệ.\")\nif os.path.exists(Test_dir):\n    best_model = create_model(num_classes)\n    best_model.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, 'alexnet_model.pth')))\n    best_model = best_model.to(device)\n    \n    test_loader = process_test_folder(Test_dir, val_transforms)\n    \n    if test_loader:\n        predict_and_submit(best_model, test_loader, train_dataset.class_to_idx, OUTPUT_PATH)\n    else:\n        print(\"Không thể tạo test loader do thiếu dữ liệu.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:14:01.170697Z","iopub.execute_input":"2025-03-09T15:14:01.171037Z","iopub.status.idle":"2025-03-09T15:14:06.357142Z","shell.execute_reply.started":"2025-03-09T15:14:01.171005Z","shell.execute_reply":"2025-03-09T15:14:06.356284Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-41-1734976b1700>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  best_model.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, 'alexnet_model.pth')))\n","output_type":"stream"},{"name":"stdout","text":"Đã tìm thấy 1499 ảnh trong thư mục test và các thư mục con.\n","output_type":"stream"},{"name":"stderr","text":"Đang dự đoán...: 100%|██████████| 24/24 [00:03<00:00,  7.35it/s]","output_type":"stream"},{"name":"stdout","text":"Đã tạo file submission với 1499 dự đoán hợp lệ.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":41}]}